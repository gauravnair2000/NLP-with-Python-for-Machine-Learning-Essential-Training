{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>body_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>\"Go until jurong point, crazy.. Available only in bugis n great world la e buffet... Cine there ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...,,,</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup final tkts 21st May 2005. Text FA to 87121 to receive ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...,,,</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>\"Nah I don't think he goes to usf, he lives around here though\",,,</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  label  \\\n",
       "0   ham   \n",
       "1   ham   \n",
       "2  spam   \n",
       "3   ham   \n",
       "4   ham   \n",
       "\n",
       "                                                                                             body_text  \n",
       "0  \"Go until jurong point, crazy.. Available only in bugis n great world la e buffet... Cine there ...  \n",
       "1                                                                     Ok lar... Joking wif u oni...,,,  \n",
       "2  Free entry in 2 a wkly comp to win FA Cup final tkts 21st May 2005. Text FA to 87121 to receive ...  \n",
       "3                                                 U dun say so early hor... U c already then say...,,,  \n",
       "4                                   \"Nah I don't think he goes to usf, he lives around here though\",,,  "
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import string\n",
    "import nltk\n",
    "pd.set_option('display.max_colwidth', 100)\n",
    "\n",
    "stopwords = nltk.corpus.stopwords.words('english')\n",
    "ps = nltk.PorterStemmer()\n",
    "\n",
    "# Read in the raw text (file downloaded from kaggle and renamed https://www.kaggle.com/uciml/sms-spam-collection-dataset)\n",
    "rawData = open(\"SMSSpamCollection.csv\").read()\n",
    "parsedData = rawData.replace(\"ham,\", \"ham\\t\")\n",
    "parsedData = parsedData.replace(\"spam,\", \"spam\\t\")\n",
    "parsedData = parsedData.replace(\"\\t\", \"\\n\").split(\"\\n\")\n",
    "parsedData = parsedData[1:]\n",
    "labelList = parsedData[0::2]\n",
    "#labelList.pop()\n",
    "textList = parsedData[1::2]\n",
    "data = pd.DataFrame({'label': labelList, 'body_text': textList})\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['ham', 'spam'], dtype=object)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['label'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>body_len</th>\n",
       "      <th>punct%</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>...</th>\n",
       "      <th>8376</th>\n",
       "      <th>8377</th>\n",
       "      <th>8378</th>\n",
       "      <th>8379</th>\n",
       "      <th>8380</th>\n",
       "      <th>8381</th>\n",
       "      <th>8382</th>\n",
       "      <th>8383</th>\n",
       "      <th>8384</th>\n",
       "      <th>8385</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>97</td>\n",
       "      <td>14.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>27</td>\n",
       "      <td>33.3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>131</td>\n",
       "      <td>6.9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>42</td>\n",
       "      <td>21.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>54</td>\n",
       "      <td>13.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 8388 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   body_len  punct%    0    1    2    3    4    5    6    7  ...  8376  8377  \\\n",
       "0        97    14.4  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   0.0   0.0   \n",
       "1        27    33.3  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   0.0   0.0   \n",
       "2       131     6.9  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   0.0   0.0   \n",
       "3        42    21.4  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   0.0   0.0   \n",
       "4        54    13.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   0.0   0.0   \n",
       "\n",
       "   8378  8379  8380  8381  8382  8383  8384  8385  \n",
       "0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "1   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "2   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "3   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "4   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "\n",
       "[5 rows x 8388 columns]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['body_len'] = data['body_text'].apply(lambda x: len(x) - x.count(\" \"))\n",
    "\n",
    "import string\n",
    "\n",
    "def count_punct(text):\n",
    "    count = sum([1 for char in text if char in string.punctuation])\n",
    "    return round(count / (len(text) - text.count(\" \")), 3) * 100\n",
    "\n",
    "data['punct%'] = data['body_text'].apply(lambda x: count_punct(x))\n",
    "\n",
    "def clean_text(text):\n",
    "    text = \"\".join([word for word in text if word not in string.punctuation])\n",
    "    tokens = re.split('\\W+', text)\n",
    "    text = [ps.stem(word) for word in tokens if word not in stopwords]\n",
    "    return text\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "tfidf_vect = TfidfVectorizer(analyzer=clean_text)\n",
    "X_tfidf = tfidf_vect.fit_transform(data['body_text'])\n",
    "\n",
    "X_features = pd.concat([data['body_len'], data['punct%'], pd.DataFrame(X_tfidf.toarray())], axis=1)\n",
    "X_features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['__abstractmethods__',\n",
       " '__annotations__',\n",
       " '__class__',\n",
       " '__delattr__',\n",
       " '__dict__',\n",
       " '__dir__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__getattribute__',\n",
       " '__getitem__',\n",
       " '__getstate__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__iter__',\n",
       " '__le__',\n",
       " '__len__',\n",
       " '__lt__',\n",
       " '__module__',\n",
       " '__ne__',\n",
       " '__new__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__setattr__',\n",
       " '__setstate__',\n",
       " '__sizeof__',\n",
       " '__str__',\n",
       " '__subclasshook__',\n",
       " '__weakref__',\n",
       " '_abc_impl',\n",
       " '_check_n_features',\n",
       " '_estimator_type',\n",
       " '_get_param_names',\n",
       " '_get_tags',\n",
       " '_make_estimator',\n",
       " '_more_tags',\n",
       " '_repr_html_',\n",
       " '_repr_html_inner',\n",
       " '_repr_mimebundle_',\n",
       " '_required_parameters',\n",
       " '_set_oob_score',\n",
       " '_validate_X_predict',\n",
       " '_validate_data',\n",
       " '_validate_estimator',\n",
       " '_validate_y_class_weight',\n",
       " 'apply',\n",
       " 'decision_path',\n",
       " 'feature_importances_',\n",
       " 'fit',\n",
       " 'get_params',\n",
       " 'predict',\n",
       " 'predict_log_proba',\n",
       " 'predict_proba',\n",
       " 'score',\n",
       " 'set_params']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "dir(RandomForestClassifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestClassifier()\n"
     ]
    }
   ],
   "source": [
    "print(RandomForestClassifier())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explore RandomForestCLassifier through Cross-validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold, cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.97399103, 0.9793722 , 0.97757848, 0.96858169, 0.97486535])"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf = RandomForestClassifier(n_jobs=-1)\n",
    "k_fold = KFold(n_splits=5)\n",
    "cross_val_score(rf, X_features, data['label'], cv=k_fold, scoring='accuracy', n_jobs=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build RandomForest model with holdout test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_recall_fscore_support as score\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_features, data['label'], test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier(n_estimators=50, max_depth=20, n_jobs=-1)\n",
    "rf_model = rf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0.05151704196199005, 'body_len'),\n",
       " (0.048547918204973596, 8371),\n",
       " (0.03211340039077488, 2023),\n",
       " (0.028156633428548475, 'punct%'),\n",
       " (0.028058241078234836, 3363),\n",
       " (0.02497231213611817, 5970),\n",
       " (0.022944573905466104, 7606),\n",
       " (0.01837095157149955, 7274),\n",
       " (0.017544918781514464, 5033),\n",
       " (0.016028728315289825, 7474),\n",
       " (0.015196062168334785, 6233),\n",
       " (0.014755645489067371, 3672),\n",
       " (0.014146498051238883, 2252),\n",
       " (0.013347498344495903, 8045),\n",
       " (0.012727357793451173, 695),\n",
       " (0.012690985196193029, 6529),\n",
       " (0.010781215882258667, 1115),\n",
       " (0.010298365782251755, 2316),\n",
       " (0.010094306969315322, 5361),\n",
       " (0.009592073750421648, 6991),\n",
       " (0.009231140778753942, 2392),\n",
       " (0.008548936776821298, 354),\n",
       " (0.008397489574342944, 1576),\n",
       " (0.00834121151855442, 392),\n",
       " (0.00776262547249227, 397),\n",
       " (0.007640008742715338, 7719),\n",
       " (0.007621043922187197, 7848),\n",
       " (0.007574272152727351, 2104),\n",
       " (0.007266475181581469, 6162),\n",
       " (0.0072595251224430715, 6295),\n",
       " (0.007029894214186041, 437),\n",
       " (0.006683794862710232, 696),\n",
       " (0.006607239359184181, 2521),\n",
       " (0.006091841757660798, 879),\n",
       " (0.006053046845635203, 615),\n",
       " (0.006030965034174568, 6120),\n",
       " (0.005948132604043398, 5245),\n",
       " (0.0055282675783794345, 440),\n",
       " (0.005348733563873362, 2302),\n",
       " (0.0051709909444664585, 4509),\n",
       " (0.005093467126434271, 3019),\n",
       " (0.004852900709059658, 2647),\n",
       " (0.004845178036715141, 5699),\n",
       " (0.004786077439070524, 360),\n",
       " (0.004582440547334835, 4535),\n",
       " (0.0045649069183466605, 822),\n",
       " (0.004358810758673085, 794),\n",
       " (0.004356312835364777, 5239),\n",
       " (0.004083552961809612, 2847),\n",
       " (0.004031068082021861, 5438),\n",
       " (0.004015313929684226, 5531),\n",
       " (0.0038621148858699605, 1574),\n",
       " (0.003854918464011954, 5967),\n",
       " (0.0038275969169985274, 5816),\n",
       " (0.0037782396529541995, 375),\n",
       " (0.003774054016050091, 294),\n",
       " (0.003628332660266341, 295),\n",
       " (0.0036015599976237183, 2425),\n",
       " (0.003595438448012144, 1108),\n",
       " (0.003417669781868546, 7693),\n",
       " (0.003408468745759272, 5318),\n",
       " (0.0033393092896764954, 442),\n",
       " (0.003316555582375932, 6730),\n",
       " (0.003239777902811543, 1024),\n",
       " (0.003211671007003793, 5522),\n",
       " (0.003194690510284225, 6951),\n",
       " (0.003194036265861485, 2154),\n",
       " (0.003181484268967402, 5797),\n",
       " (0.0030864328662502617, 6374),\n",
       " (0.0030737031683132567, 5030),\n",
       " (0.003022773525705682, 2053),\n",
       " (0.003013787847460287, 3069),\n",
       " (0.0029452607608670307, 426),\n",
       " (0.0028572928467799686, 1837),\n",
       " (0.002818754031402102, 7716),\n",
       " (0.002779051432421583, 8097),\n",
       " (0.002743124039859554, 2163),\n",
       " (0.0027402036101205206, 6857),\n",
       " (0.0026804225554868132, 3117),\n",
       " (0.0026608026373089178, 7574),\n",
       " (0.002550814959929811, 368),\n",
       " (0.002515384282640828, 1121),\n",
       " (0.0024873780852868246, 8326),\n",
       " (0.002440248686406325, 1083),\n",
       " (0.002413448424032621, 5842),\n",
       " (0.002375536533282066, 2949),\n",
       " (0.0023319105629279087, 819),\n",
       " (0.002291657660254385, 7950),\n",
       " (0.002260638604564937, 1442),\n",
       " (0.0022431115678911585, 338),\n",
       " (0.0022048625758076933, 7619),\n",
       " (0.002194693071543422, 8052),\n",
       " (0.002082975170848901, 5742),\n",
       " (0.0020571687323020756, 1868),\n",
       " (0.0019326294419809726, 2828),\n",
       " (0.0018801162741421589, 3454),\n",
       " (0.0018736917318654587, 4041),\n",
       " (0.0018698002030608845, 4508),\n",
       " (0.0018480058197587208, 471),\n",
       " (0.0018479507623880963, 2471),\n",
       " (0.0018440854166760976, 5752),\n",
       " (0.0018410867721522515, 3167),\n",
       " (0.0018107399017354704, 4730),\n",
       " (0.0018028964249695828, 5036),\n",
       " (0.0017480800369046182, 7763),\n",
       " (0.0017063238169505628, 6227),\n",
       " (0.0017030568696638374, 5193),\n",
       " (0.0016645614316543088, 1398),\n",
       " (0.001661516069331443, 1535),\n",
       " (0.0016188323237145846, 2737),\n",
       " (0.001556277217827291, 4617),\n",
       " (0.0015137209134344165, 7635),\n",
       " (0.0015136496387956292, 4917),\n",
       " (0.0015050855585678024, 5953),\n",
       " (0.0014958163476112216, 882),\n",
       " (0.0014686978032376946, 6621),\n",
       " (0.001440655293838521, 8309),\n",
       " (0.0014270225992661356, 3520),\n",
       " (0.0014023429339825122, 6479),\n",
       " (0.00135808062397409, 5088),\n",
       " (0.0013563307027142956, 2515),\n",
       " (0.0013226731517114035, 3320),\n",
       " (0.0013066702434121, 7218),\n",
       " (0.001298462684597045, 6506),\n",
       " (0.0012830763314882585, 311),\n",
       " (0.0012813653593310623, 50),\n",
       " (0.001275387044423522, 984),\n",
       " (0.0012584667254658174, 3371),\n",
       " (0.0012556945820804328, 6238),\n",
       " (0.001221956201380369, 3548),\n",
       " (0.0012205466243656027, 1106),\n",
       " (0.0012203861569084666, 7953),\n",
       " (0.0012048239533326364, 1063),\n",
       " (0.0011909322817666695, 2147),\n",
       " (0.0011694832798815249, 7801),\n",
       " (0.0011673502185313642, 2722),\n",
       " (0.0011588637141442181, 3013),\n",
       " (0.0011522080957707015, 2573),\n",
       " (0.0011328675523130816, 6495),\n",
       " (0.0011105856606029847, 5145),\n",
       " (0.001086051262710505, 54),\n",
       " (0.001073657002001551, 3899),\n",
       " (0.0010702934413326383, 56),\n",
       " (0.0010693068377544029, 2394),\n",
       " (0.001038538171001572, 5494),\n",
       " (0.0010263802859411812, 3601),\n",
       " (0.0010260385210009444, 1179),\n",
       " (0.0010251824220181935, 292),\n",
       " (0.0010133678730571494, 573),\n",
       " (0.0010034758947042922, 5383),\n",
       " (0.0009851239349034664, 8076),\n",
       " (0.0009580360646667836, 364),\n",
       " (0.0009472526852317613, 7901),\n",
       " (0.0009434683402776204, 4861),\n",
       " (0.0009385202305364429, 3842),\n",
       " (0.0009363833945884976, 1094),\n",
       " (0.0009288652074127115, 979),\n",
       " (0.0009272461961328915, 3128),\n",
       " (0.0009118151312283826, 6782),\n",
       " (0.0008968175119451755, 2382),\n",
       " (0.0008910732724452281, 1117),\n",
       " (0.0008888821779572332, 2789),\n",
       " (0.0008853837122869278, 53),\n",
       " (0.0008620967652343725, 296),\n",
       " (0.0008619086562322714, 3051),\n",
       " (0.0008590727867533309, 2051),\n",
       " (0.0008350706898822925, 1036),\n",
       " (0.0008350173195109995, 118),\n",
       " (0.0008186831425118653, 2320),\n",
       " (0.0008172432638011782, 2105),\n",
       " (0.0008065485678306152, 4452),\n",
       " (0.0008035134510065421, 5889),\n",
       " (0.0008005949058958884, 3578),\n",
       " (0.0007969107832336084, 524),\n",
       " (0.0007934306060555369, 4971),\n",
       " (0.0007932324377302532, 2428),\n",
       " (0.0007840868536243725, 6080),\n",
       " (0.0007786407076739118, 439),\n",
       " (0.0007767723875139254, 3704),\n",
       " (0.0007604579095039549, 8228),\n",
       " (0.0007581123338005924, 1421),\n",
       " (0.0007578820963015766, 435),\n",
       " (0.0007500388993886693, 6791),\n",
       " (0.0007392403006612807, 5513),\n",
       " (0.0007382733283222313, 5790),\n",
       " (0.000737274016810282, 2341),\n",
       " (0.0007296372531943659, 6340),\n",
       " (0.000725334938084449, 4707),\n",
       " (0.0007253101517400171, 7611),\n",
       " (0.0007181655488237357, 4178),\n",
       " (0.0007062649665447937, 4868),\n",
       " (0.0006981431838915056, 1135),\n",
       " (0.0006942472745356667, 4862),\n",
       " (0.0006906329489094685, 5390),\n",
       " (0.0006818197050681138, 455),\n",
       " (0.0006771081841147469, 7838),\n",
       " (0.0006719267203934358, 869),\n",
       " (0.0006712859651324725, 7496),\n",
       " (0.0006694112590035811, 3375),\n",
       " (0.000660613035646895, 7686),\n",
       " (0.0006595315193848266, 885),\n",
       " (0.0006575907301927726, 6535),\n",
       " (0.0006442608012840707, 7058),\n",
       " (0.0006413050640326086, 2325),\n",
       " (0.000640442267101972, 156),\n",
       " (0.0006269498821057513, 5076),\n",
       " (0.000621450810132992, 6984),\n",
       " (0.0006169611859737918, 5488),\n",
       " (0.0006110968336767021, 8188),\n",
       " (0.0006082651078616448, 7765),\n",
       " (0.0006019644855018943, 5096),\n",
       " (0.0006003350580694184, 7876),\n",
       " (0.0005964677679696645, 4548),\n",
       " (0.0005862985873772062, 4304),\n",
       " (0.0005773678014012791, 3242),\n",
       " (0.0005734470002991365, 4876),\n",
       " (0.0005665017997993165, 6223),\n",
       " (0.00056552391554018, 450),\n",
       " (0.0005649646143883715, 4997),\n",
       " (0.0005569523835313601, 3408),\n",
       " (0.0005568901196236648, 402),\n",
       " (0.0005501653370102366, 5445),\n",
       " (0.0005390562192731036, 2426),\n",
       " (0.0005375677489310265, 5104),\n",
       " (0.0005337586596604878, 7626),\n",
       " (0.0005288618867891282, 841),\n",
       " (0.000523479780179414, 5791),\n",
       " (0.0005212351249240125, 5218),\n",
       " (0.0005165818664658427, 6149),\n",
       " (0.0005162735257172699, 3168),\n",
       " (0.0005153603837325803, 6938),\n",
       " (0.0005146277016863114, 2963),\n",
       " (0.0005141225572027748, 1049),\n",
       " (0.0005103150627683172, 2519),\n",
       " (0.0005065630753570511, 4075),\n",
       " (0.0005054479374169693, 962),\n",
       " (0.000504764229438362, 1955),\n",
       " (0.0005008675922890166, 529),\n",
       " (0.0005000058427212605, 1035),\n",
       " (0.0004978844955570818, 5827),\n",
       " (0.0004972357194739257, 1119),\n",
       " (0.0004946660973926384, 2813),\n",
       " (0.0004932866175993957, 8356),\n",
       " (0.0004921599420071955, 3931),\n",
       " (0.000491565649156922, 4168),\n",
       " (0.0004890997066851526, 6277),\n",
       " (0.00048728295172608907, 7299),\n",
       " (0.00047965065939184454, 1009),\n",
       " (0.0004796184491682712, 2002),\n",
       " (0.00047326326372841093, 2281),\n",
       " (0.0004693187398864428, 6427),\n",
       " (0.00046758144891969044, 612),\n",
       " (0.00046607908917809177, 443),\n",
       " (0.00045988732573608445, 3057),\n",
       " (0.00045819122490154524, 459),\n",
       " (0.0004549429892294809, 7701),\n",
       " (0.000453841095184253, 1194),\n",
       " (0.0004518573909886587, 1267),\n",
       " (0.0004479818549274585, 580),\n",
       " (0.00044772692596818707, 2107),\n",
       " (0.0004468628746694961, 325),\n",
       " (0.0004401656330939277, 4058),\n",
       " (0.0004391152317134246, 7770),\n",
       " (0.0004379188759632885, 1089),\n",
       " (0.00043581916449873624, 7752),\n",
       " (0.0004292498238597411, 594),\n",
       " (0.0004275766916799232, 0),\n",
       " (0.00042357545137816833, 444),\n",
       " (0.00041976270436206093, 670),\n",
       " (0.0004184480688841908, 966),\n",
       " (0.0004090505482535713, 370),\n",
       " (0.0004079295103485309, 381),\n",
       " (0.00040632782392753113, 5338),\n",
       " (0.0004019365178149655, 2156),\n",
       " (0.0004008774522702787, 3507),\n",
       " (0.00039883701712224907, 307),\n",
       " (0.0003940117281507506, 884),\n",
       " (0.0003928877511126099, 4735),\n",
       " (0.00038938841387026657, 1959),\n",
       " (0.0003849689645584231, 6692),\n",
       " (0.0003818534617412767, 4023),\n",
       " (0.0003768998514288496, 949),\n",
       " (0.0003753842977833636, 924),\n",
       " (0.00037526939811423647, 1268),\n",
       " (0.0003747048754678894, 1592),\n",
       " (0.00037283489554920305, 6485),\n",
       " (0.0003726985508451822, 2944),\n",
       " (0.00037245026837559434, 282),\n",
       " (0.00037149912259527363, 4940),\n",
       " (0.00036563383598320673, 2640),\n",
       " (0.0003654363464200072, 3532),\n",
       " (0.0003598714599179459, 4608),\n",
       " (0.00035956278358218916, 6225),\n",
       " (0.0003579115647157396, 7051),\n",
       " (0.000357246418857419, 2929),\n",
       " (0.00035478371780028195, 891),\n",
       " (0.0003544560606447653, 7200),\n",
       " (0.0003544399297373693, 7899),\n",
       " (0.0003542066569132701, 2408),\n",
       " (0.0003539818164831165, 770),\n",
       " (0.0003528187661776831, 6856),\n",
       " (0.00034929191738398784, 544),\n",
       " (0.00034809386254894715, 6020),\n",
       " (0.00034682347905689247, 7737),\n",
       " (0.00034112674971551127, 8253),\n",
       " (0.00033965661209800285, 6956),\n",
       " (0.00033905231858866435, 7839),\n",
       " (0.00033703288071940904, 1604),\n",
       " (0.0003368064954260549, 4061),\n",
       " (0.00033320605895797024, 6107),\n",
       " (0.0003322804984510951, 893),\n",
       " (0.0003319710864792944, 645),\n",
       " (0.00033143761107846823, 6143),\n",
       " (0.0003295869281051557, 977),\n",
       " (0.0003292757268234757, 483),\n",
       " (0.00032864227656407424, 6844),\n",
       " (0.00032751714980554583, 5502),\n",
       " (0.0003271650087272643, 3307),\n",
       " (0.00032537400409319054, 1104),\n",
       " (0.0003239636801151316, 27),\n",
       " (0.00032368101487298623, 922),\n",
       " (0.0003225076827216764, 421),\n",
       " (0.0003221839218334439, 1488),\n",
       " (0.00032188128604449066, 2041),\n",
       " (0.00032165944588183066, 4050),\n",
       " (0.0003211834733438029, 7842),\n",
       " (0.00032073165094611915, 3238),\n",
       " (0.0003188319192025483, 2836),\n",
       " (0.0003177794314930681, 142),\n",
       " (0.00031730206823110766, 735),\n",
       " (0.000316263013348703, 4261),\n",
       " (0.0003152976950980197, 96),\n",
       " (0.0003138585861342649, 1450),\n",
       " (0.0003138133009920572, 939),\n",
       " (0.000313017957338682, 1208),\n",
       " (0.0003124483143382922, 3729),\n",
       " (0.00030468528896520594, 6658),\n",
       " (0.0003043817144992845, 7097),\n",
       " (0.00030390888964892655, 84),\n",
       " (0.0002983128427975001, 2131),\n",
       " (0.0002981168082508518, 3169),\n",
       " (0.0002978014781173424, 312),\n",
       " (0.0002971905596925891, 1047),\n",
       " (0.00029557854717289804, 2842),\n",
       " (0.00029391125795180943, 6998),\n",
       " (0.0002908736858204355, 1079),\n",
       " (0.00029087208239552233, 4688),\n",
       " (0.0002904208006441312, 7182),\n",
       " (0.00028954943707824605, 457),\n",
       " (0.00028845176631476436, 3718),\n",
       " (0.000288228455475234, 4659),\n",
       " (0.000287872815088616, 889),\n",
       " (0.0002878118536925976, 2598),\n",
       " (0.0002877065897856273, 556),\n",
       " (0.0002874523847750222, 2416),\n",
       " (0.0002821190680259614, 214),\n",
       " (0.0002817036081617329, 2213),\n",
       " (0.000279944694998998, 1939),\n",
       " (0.00027939844815359993, 2172),\n",
       " (0.0002751635583180386, 4619),\n",
       " (0.0002750880069252828, 4650),\n",
       " (0.00027267611811579884, 4586),\n",
       " (0.0002719831126404498, 65),\n",
       " (0.00027005034300842443, 1876),\n",
       " (0.0002693434233516712, 8115),\n",
       " (0.0002691281450032264, 4070),\n",
       " (0.00026851491448758356, 1337),\n",
       " (0.0002676031411156941, 7608),\n",
       " (0.0002664523684082997, 1185),\n",
       " (0.0002663665377465478, 8231),\n",
       " (0.0002657640961639694, 8080),\n",
       " (0.0002648846496164808, 7924),\n",
       " (0.00026468394456751496, 3971),\n",
       " (0.0002642539103220596, 7402),\n",
       " (0.0002639168814795518, 597),\n",
       " (0.0002631302562947559, 3950),\n",
       " (0.0002617804700319377, 741),\n",
       " (0.0002615675573857087, 6084),\n",
       " (0.00026023282968535855, 739),\n",
       " (0.00026013067251704554, 815),\n",
       " (0.00026000889987237865, 4874),\n",
       " (0.0002555045073395093, 6515),\n",
       " (0.00025520583831441614, 795),\n",
       " (0.00025412318460351344, 351),\n",
       " (0.00025390703732380094, 7540),\n",
       " (0.00025254386187227416, 2831),\n",
       " (0.00025204660592964535, 2270),\n",
       " (0.00025126153978507413, 5753),\n",
       " (0.00024863301452719965, 5685),\n",
       " (0.00024772886589465135, 2003),\n",
       " (0.00024746941658504977, 7257),\n",
       " (0.00024738905642820286, 93),\n",
       " (0.0002471399131379789, 4672),\n",
       " (0.00024440485205244204, 4722),\n",
       " (0.00024391490036033018, 5925),\n",
       " (0.00024316525061498565, 2918),\n",
       " (0.0002422872062670258, 4984),\n",
       " (0.0002407819981208396, 1595),\n",
       " (0.00023974474487512912, 2602),\n",
       " (0.00023869685358112028, 2767),\n",
       " (0.00023861422648678476, 4724),\n",
       " (0.00023854396986453148, 5535),\n",
       " (0.00023852142382187183, 3001),\n",
       " (0.0002384361476282012, 7201),\n",
       " (0.00023690289062578156, 1118),\n",
       " (0.00023666274093547699, 7244),\n",
       " (0.00023496250593425122, 2247),\n",
       " (0.00023376135235335307, 6686),\n",
       " (0.00023228590453242413, 7440),\n",
       " (0.00023108316168917578, 6825),\n",
       " (0.00023104569883225447, 76),\n",
       " (0.00023042485477964335, 1016),\n",
       " (0.00023024839375393273, 745),\n",
       " (0.0002299640708278844, 6654),\n",
       " (0.0002282438714344945, 1884),\n",
       " (0.0002276653835183046, 3908),\n",
       " (0.00022715047274296434, 2508),\n",
       " (0.00022648389382754684, 314),\n",
       " (0.0002259868523955565, 8101),\n",
       " (0.0002252363420011436, 1740),\n",
       " (0.00022441210041541305, 894),\n",
       " (0.0002240616238234102, 8132),\n",
       " (0.00022399231008058632, 260),\n",
       " (0.00022195228386519953, 1021),\n",
       " (0.00022155922576840682, 4657),\n",
       " (0.00022148603235838126, 4112),\n",
       " (0.00022091252192139532, 821),\n",
       " (0.00022071437435407148, 2827),\n",
       " (0.00022008865711041148, 324),\n",
       " (0.00021945879715683963, 3203),\n",
       " (0.00021756076928957196, 3615),\n",
       " (0.0002168502392615449, 2230),\n",
       " (0.00021597397572217905, 6781),\n",
       " (0.00021429950714688776, 3811),\n",
       " (0.00020972830731355019, 217),\n",
       " (0.00020964844752493147, 870),\n",
       " (0.00020930090933910645, 7897),\n",
       " (0.00020913116395650778, 6530),\n",
       " (0.00020889231837044317, 4240),\n",
       " (0.00020851282114594312, 4652),\n",
       " (0.00020841081267655552, 7309),\n",
       " (0.00020778121157482128, 4022),\n",
       " (0.00020646633522901646, 1370),\n",
       " (0.00020483985894294364, 3526),\n",
       " (0.0002046894173913081, 6727),\n",
       " (0.00020408771745716785, 8121),\n",
       " (0.00020372301345235574, 22),\n",
       " (0.00020364253386592055, 577),\n",
       " (0.00020354842315739005, 5557),\n",
       " (0.00020354538587351474, 7964),\n",
       " (0.00020339698849049934, 1377),\n",
       " (0.00020248297399633685, 293),\n",
       " (0.00020243324889554872, 6172),\n",
       " (0.0002022712445689264, 7261),\n",
       " (0.00020173381061564292, 861),\n",
       " (0.0002013615653577318, 3954),\n",
       " (0.00019843277439099332, 34),\n",
       " (0.0001973732125498714, 6891),\n",
       " (0.0001969419921116335, 4297),\n",
       " (0.00019641453400384473, 4196),\n",
       " (0.00019573473697798372, 2123),\n",
       " (0.00019372398570458098, 5119),\n",
       " (0.0001936479438396473, 4089),\n",
       " (0.00019358389616587344, 6670),\n",
       " (0.00019216035652803464, 2680),\n",
       " (0.00019190538228927234, 5543),\n",
       " (0.00019145079983079105, 5824),\n",
       " (0.00019093115512638838, 5187),\n",
       " (0.00019043337284442352, 4685),\n",
       " (0.00018993889313194629, 8213),\n",
       " (0.00018986158510248877, 7591),\n",
       " (0.00018883034368684528, 705),\n",
       " (0.00018816349421267836, 4035),\n",
       " (0.0001876562380611323, 6683),\n",
       " (0.00018704773144095595, 646),\n",
       " (0.00018699499081873783, 7284),\n",
       " (0.00018582164776534358, 6669),\n",
       " (0.0001857032968324642, 4391),\n",
       " (0.00018556124980954127, 4691),\n",
       " (0.00018534621024859726, 3691),\n",
       " (0.0001832572395407567, 4387),\n",
       " (0.00018302024519529876, 3121),\n",
       " (0.00018256457518354115, 7006),\n",
       " (0.00018238913793133235, 4743),\n",
       " (0.0001808820085679814, 6906),\n",
       " (0.00017980691824085474, 6489),\n",
       " (0.00017978097422355173, 3765),\n",
       " (0.0001797035129772058, 6380),\n",
       " (0.0001793158069407773, 4527),\n",
       " (0.0001788214434849583, 5053),\n",
       " (0.00017802991266814303, 3972),\n",
       " (0.00017798640628339225, 105),\n",
       " (0.0001776760231127918, 401),\n",
       " (0.00017693880661831605, 441),\n",
       " (0.0001768334753219138, 7350),\n",
       " (0.00017623774989002555, 3391),\n",
       " (0.00017596473816871598, 8138),\n",
       " (0.0001759241941976748, 1335),\n",
       " (0.00017571024582221044, 4324),\n",
       " (0.00017552084389093573, 5604),\n",
       " (0.0001750657786697963, 6473),\n",
       " (0.00017499494510978255, 2047),\n",
       " (0.00017493301328497027, 860),\n",
       " (0.00017364258977854233, 6242),\n",
       " (0.00017245987861862905, 2518),\n",
       " (0.0001719829147629001, 7263),\n",
       " (0.0001719295176633362, 169),\n",
       " (0.0001712610659932015, 5190),\n",
       " (0.0001708310501901761, 6166),\n",
       " (0.0001706613277778187, 7974),\n",
       " (0.00016905157145226084, 81),\n",
       " (0.00016879270293687875, 7290),\n",
       " (0.00016861838576762815, 928),\n",
       " (0.0001685383646495402, 6750),\n",
       " (0.00016846053439504771, 5921),\n",
       " (0.0001684184839826696, 5698),\n",
       " (0.00016761044164526209, 7426),\n",
       " (0.00016754415050518223, 7433),\n",
       " (0.00016751571536841273, 7811),\n",
       " (0.00016600768436431622, 6299),\n",
       " (0.00016597720454221608, 4846),\n",
       " (0.0001658016602759665, 3713),\n",
       " (0.00016575078357919588, 6050),\n",
       " (0.0001657015336115894, 1634),\n",
       " (0.00016564027217972892, 6434),\n",
       " (0.0001651682919618725, 549),\n",
       " (0.00016481702534475943, 145),\n",
       " (0.00016382503737653924, 5178),\n",
       " (0.00016371257730972376, 5192),\n",
       " (0.00016357352020163605, 7057),\n",
       " (0.00016315139023672238, 2432),\n",
       " (0.00016307570979641608, 4676),\n",
       " (0.00016306243977533247, 1716),\n",
       " (0.000162883705475404, 2932),\n",
       " (0.00016283489401473284, 3639),\n",
       " (0.00016241361517682583, 3839),\n",
       " (0.00016201169125553395, 1490),\n",
       " (0.00016143546714821394, 209),\n",
       " (0.0001606446967649376, 122),\n",
       " (0.0001605385675779368, 1642),\n",
       " (0.00016030486782999607, 2369),\n",
       " (0.00016008269523645153, 871),\n",
       " (0.00016001447780380083, 8239),\n",
       " (0.00015942764196860237, 7936),\n",
       " (0.0001588891731614804, 8189),\n",
       " (0.00015862497648622503, 132),\n",
       " (0.00015761865321236774, 5067),\n",
       " (0.0001569556945657547, 194),\n",
       " (0.00015652899952691882, 3475),\n",
       " (0.00015652571285574315, 7129),\n",
       " (0.00015616703053042253, 4961),\n",
       " (0.00015534441190472948, 5926),\n",
       " (0.00015511484076584484, 8039),\n",
       " (0.00015499356994487976, 6298),\n",
       " (0.00015492056805028353, 4996),\n",
       " (0.00015443183674330842, 7456),\n",
       " (0.0001543761468740885, 3896),\n",
       " (0.00015390293726571326, 6085),\n",
       " (0.0001533272905991415, 3994),\n",
       " (0.0001523553997898746, 64),\n",
       " (0.00015211407322316127, 1544),\n",
       " (0.000151310950356819, 6235),\n",
       " (0.0001512978101512615, 3740),\n",
       " (0.00015087834389458516, 2068),\n",
       " (0.00015041124565216808, 3438),\n",
       " (0.00015040573847551597, 1840),\n",
       " (0.0001502669921881594, 1581),\n",
       " (0.00014944069504571776, 3843),\n",
       " (0.00014911154949412238, 5979),\n",
       " (0.0001483256902242708, 5715),\n",
       " (0.0001480549032192098, 6068),\n",
       " (0.0001478321436738828, 4084),\n",
       " (0.0001477535802256216, 1505),\n",
       " (0.00014772690215026838, 731),\n",
       " (0.00014741389155002607, 6810),\n",
       " (0.0001467592332053345, 4581),\n",
       " (0.00014641977920295453, 4106),\n",
       " (0.00014607706927980145, 1995),\n",
       " (0.00014568758645103962, 1039),\n",
       " (0.0001453893871525026, 1577),\n",
       " (0.00014491927085620606, 6549),\n",
       " (0.00014425080434466898, 7985),\n",
       " (0.00014423613895598835, 1038),\n",
       " (0.00014330333976927823, 4342),\n",
       " (0.00014324818002057495, 4005),\n",
       " (0.0001430684523851305, 7451),\n",
       " (0.00014263970767055515, 2032),\n",
       " (0.00014248056651021616, 6616),\n",
       " (0.00014239194617685902, 1067),\n",
       " (0.0001414719699055389, 174),\n",
       " (0.00014129800768243134, 6429),\n",
       " (0.00014103366854173867, 2695),\n",
       " (0.0001403665180827, 8365),\n",
       " (0.00014020385176256544, 1951),\n",
       " (0.00013976196289341004, 4814),\n",
       " (0.00013962597389999433, 2706),\n",
       " (0.00013926952618963556, 4560),\n",
       " (0.00013791517819770703, 6898),\n",
       " (0.00013790558472229328, 6602),\n",
       " (0.00013767274390633755, 537),\n",
       " (0.00013739058475067544, 7424),\n",
       " (0.00013725761297328723, 1269),\n",
       " (0.0001367638656796336, 383),\n",
       " (0.00013651434812025337, 1803),\n",
       " (0.00013626172672782426, 4684),\n",
       " (0.00013618369931151566, 4832),\n",
       " (0.00013606960816112902, 3668),\n",
       " (0.0001360385779113688, 5451),\n",
       " (0.00013470206164993667, 7857),\n",
       " (0.00013419280406950005, 4557),\n",
       " (0.00013358588464247898, 3268),\n",
       " (0.0001335562989358271, 456),\n",
       " (0.00013257036616705952, 1189),\n",
       " (0.00013230360558249125, 5093),\n",
       " (0.0001317204154518038, 2079),\n",
       " (0.0001313301286624224, 2535),\n",
       " (0.0001305338429035457, 3330),\n",
       " (0.0001299042032861972, 3469),\n",
       " (0.00012833116742896883, 3426),\n",
       " (0.00012788005106300498, 3263),\n",
       " (0.00012707300458306684, 1761),\n",
       " (0.00012648068244575618, 7345),\n",
       " (0.00012616712256945315, 2454),\n",
       " (0.00012548504102668647, 7002),\n",
       " (0.0001248889072299573, 6976),\n",
       " (0.0001239490507856839, 4632),\n",
       " (0.00012361653880568085, 848),\n",
       " (0.00012358766579828026, 6656),\n",
       " (0.00012240487230289704, 5034),\n",
       " (0.00012208264504051476, 4318),\n",
       " (0.00012199768100780491, 8266),\n",
       " (0.00012119652767763425, 3286),\n",
       " (0.00012038935484173946, 7864),\n",
       " (0.00011994064580799352, 4412),\n",
       " (0.00011976474649227107, 5486),\n",
       " (0.0001195501559270132, 3388),\n",
       " (0.0001194197134245275, 6538),\n",
       " (0.00011916015241642489, 6175),\n",
       " (0.00011847893628215702, 2540),\n",
       " (0.0001180281112395383, 3311),\n",
       " (0.00011773265233916423, 107),\n",
       " (0.00011707534340836866, 3162),\n",
       " (0.00011549919701342599, 7688),\n",
       " (0.00011534154904224577, 7547),\n",
       " (0.00011484022776079425, 1619),\n",
       " (0.00011481059940205816, 4279),\n",
       " (0.00011471746547522883, 3394),\n",
       " (0.00011407124586397252, 8030),\n",
       " (0.00011385874908528677, 7994),\n",
       " (0.00011360983719626026, 7731),\n",
       " (0.00011345730778752845, 6296),\n",
       " (0.00011299875359616109, 127),\n",
       " (0.00011173530827352373, 7000),\n",
       " (0.00011154243490822277, 6575),\n",
       " (0.00011153155098450478, 7236),\n",
       " (0.00011138642649877965, 3513),\n",
       " (0.00011100379480444438, 3397),\n",
       " (0.00011100290019876196, 559),\n",
       " (0.00011065691521123123, 1608),\n",
       " (0.00010931515980446112, 2583),\n",
       " (0.00010897921619271067, 4639),\n",
       " (0.00010890904083989575, 4150),\n",
       " (0.00010799528333209384, 4394),\n",
       " (0.00010788994110483376, 4786),\n",
       " (0.00010778418122843246, 5210),\n",
       " (0.00010751303564850151, 6256),\n",
       " (0.00010747470914764147, 5198),\n",
       " (0.00010710680839695878, 4982),\n",
       " (0.00010612546418454573, 2547),\n",
       " (0.00010597950254511964, 8296),\n",
       " (0.00010588876244238446, 7348),\n",
       " (0.00010556533562013117, 947),\n",
       " (0.00010550996566195724, 291),\n",
       " (0.00010539714812083715, 584),\n",
       " (0.00010523304164075337, 151),\n",
       " (0.0001050665715624349, 3220),\n",
       " (0.00010477700893345107, 1560),\n",
       " (0.00010459586204122536, 994),\n",
       " (0.00010446138498978022, 6691),\n",
       " (0.00010441779311292387, 5027),\n",
       " (0.00010375809430979175, 7391),\n",
       " (0.00010335597350840697, 1722),\n",
       " (0.00010328514609499328, 2979),\n",
       " (0.00010314821175656971, 6409),\n",
       " (0.00010294518564247956, 5296),\n",
       " (0.00010294518564247955, 1462),\n",
       " (0.00010290269356532716, 3767),\n",
       " (0.00010284007823868459, 2751),\n",
       " (0.00010241022181853575, 6944),\n",
       " (0.00010226790655041567, 7115),\n",
       " (0.00010217046668176499, 1633),\n",
       " (0.00010209581598938278, 8051),\n",
       " (0.0001019245795064103, 7553),\n",
       " (0.00010186658331957307, 2585),\n",
       " (0.00010175498891098321, 6788),\n",
       " (0.00010171806864841523, 2485),\n",
       " (0.00010121710375145033, 5833),\n",
       " (0.0001004021343105974, 872),\n",
       " (0.00010037784323098394, 2881),\n",
       " (0.00010012572074796647, 4692),\n",
       " (9.949663495987431e-05, 475),\n",
       " (9.93894944721272e-05, 1060),\n",
       " (9.938593834843702e-05, 28),\n",
       " (9.93350504657195e-05, 7827),\n",
       " (9.923081068090999e-05, 4201),\n",
       " (9.912660699684862e-05, 6854),\n",
       " (9.895355704291863e-05, 6707),\n",
       " (9.888313393845971e-05, 5122),\n",
       " (9.827253551149235e-05, 1975),\n",
       " (9.808110050693236e-05, 248),\n",
       " (9.79965367309352e-05, 7965),\n",
       " (9.793560154094599e-05, 5345),\n",
       " (9.778727182532237e-05, 610),\n",
       " (9.77645044002165e-05, 2595),\n",
       " (9.738255031651488e-05, 3604),\n",
       " (9.729906756483218e-05, 4631),\n",
       " (9.709308186111119e-05, 5641),\n",
       " (9.70691751806131e-05, 8032),\n",
       " (9.664713503155224e-05, 5075),\n",
       " (9.647846298249038e-05, 694),\n",
       " (9.639419742202191e-05, 4254),\n",
       " (9.638295769988039e-05, 59),\n",
       " (9.627281460218946e-05, 6680),\n",
       " (9.618618809314389e-05, 8303),\n",
       " (9.595522664222602e-05, 3282),\n",
       " (9.528924522400534e-05, 4247),\n",
       " (9.526746530670158e-05, 7476),\n",
       " (9.505808892572423e-05, 5495),\n",
       " (9.497575060107898e-05, 7788),\n",
       " (9.472143025011713e-05, 7356),\n",
       " (9.447274440662738e-05, 3058),\n",
       " (9.444297498281853e-05, 8021),\n",
       " (9.398563830598408e-05, 992),\n",
       " (9.397379512500711e-05, 2620),\n",
       " (9.379752368927647e-05, 7551),\n",
       " (9.357312423585356e-05, 1602),\n",
       " (9.299193211299415e-05, 8311),\n",
       " (9.280750151174818e-05, 834),\n",
       " (9.268802549977156e-05, 693),\n",
       " (9.246887332495062e-05, 1960),\n",
       " (9.236704354695804e-05, 4192),\n",
       " (9.236020302350726e-05, 1214),\n",
       " (9.221537653723521e-05, 4886),\n",
       " (9.208666662260485e-05, 7305),\n",
       " (9.171014586358811e-05, 5066),\n",
       " (9.170423406472894e-05, 742),\n",
       " (9.157955187765145e-05, 3990),\n",
       " (9.143592423550361e-05, 1762),\n",
       " (9.102317838963425e-05, 1586),\n",
       " (9.087088791840073e-05, 4524),\n",
       " (9.049493686215103e-05, 1588),\n",
       " (9.018448519751848e-05, 2489),\n",
       " (9.010335414240742e-05, 746),\n",
       " (9.00890193572467e-05, 6941),\n",
       " (8.981314321248959e-05, 3399),\n",
       " (8.90263830886134e-05, 5263),\n",
       " (8.892535333055452e-05, 6293),\n",
       " (8.866142025083044e-05, 2273),\n",
       " (8.821220188375556e-05, 3428),\n",
       " (8.793082252700163e-05, 499),\n",
       " (8.792877940831406e-05, 1003),\n",
       " (8.779530335189514e-05, 3417),\n",
       " (8.772612300125665e-05, 5846),\n",
       " (8.764367315035429e-05, 3944),\n",
       " (8.729824493178757e-05, 1420),\n",
       " (8.662439776006949e-05, 74),\n",
       " (8.65703144330862e-05, 5783),\n",
       " (8.616234794496141e-05, 6421),\n",
       " (8.604842670672775e-05, 4611),\n",
       " (8.566243877954748e-05, 4794),\n",
       " (8.556219254254352e-05, 2712),\n",
       " (8.534152991504111e-05, 6376),\n",
       " (8.503668147631322e-05, 3074),\n",
       " (8.502562499736233e-05, 4902),\n",
       " (8.490064208025342e-05, 2024),\n",
       " (8.471634309578938e-05, 6634),\n",
       " (8.451927382355595e-05, 781),\n",
       " (8.38812623753537e-05, 6202),\n",
       " (8.356729764197986e-05, 4568),\n",
       " (8.319872866855877e-05, 234),\n",
       " (8.240166560854174e-05, 6948),\n",
       " (8.23770993255643e-05, 5977),\n",
       " (8.212497272831916e-05, 7929),\n",
       " (8.210385898897818e-05, 6674),\n",
       " (8.162387211542266e-05, 1279),\n",
       " (8.122040095695207e-05, 210),\n",
       " (8.083700319248852e-05, 960),\n",
       " (8.079401644284185e-05, 6290),\n",
       " (8.071968537972288e-05, 1031),\n",
       " (7.991803386305182e-05, 6911),\n",
       " (7.99130128337071e-05, 2381),\n",
       " (7.974746126219365e-05, 3387),\n",
       " (7.945250864145758e-05, 7673),\n",
       " (7.902373819752475e-05, 2058),\n",
       " (7.900991833621533e-05, 150),\n",
       " (7.89218843981739e-05, 1849),\n",
       " (7.890111566375412e-05, 14),\n",
       " (7.882427863319558e-05, 3065),\n",
       " (7.877756609987244e-05, 6073),\n",
       " (7.868444884108299e-05, 1206),\n",
       " (7.829997993061135e-05, 2895),\n",
       " (7.819665559167323e-05, 5929),\n",
       " (7.810355542823691e-05, 1366),\n",
       " (7.806643223098818e-05, 1220),\n",
       " (7.795674644743003e-05, 3680),\n",
       " (7.777480003013802e-05, 2298),\n",
       " (7.766835566057234e-05, 5251),\n",
       " (7.735958329545042e-05, 1860),\n",
       " (7.724860066177904e-05, 57),\n",
       " (7.717469767013078e-05, 4711),\n",
       " (7.640267649636734e-05, 647),\n",
       " (7.542930078431045e-05, 5560),\n",
       " (7.454902765167516e-05, 4623),\n",
       " (7.435303196330865e-05, 1227),\n",
       " (7.394106366309322e-05, 2980),\n",
       " (7.384426328945988e-05, 2466),\n",
       " (7.374128572817808e-05, 5108),\n",
       " (7.341956426036312e-05, 1460),\n",
       " (7.338689951505545e-05, 7329),\n",
       " (7.316981875326908e-05, 4038),\n",
       " (7.30065437047077e-05, 68),\n",
       " (7.26224989122e-05, 180),\n",
       " (7.221907611448527e-05, 6141),\n",
       " (7.207453807399667e-05, 286),\n",
       " (7.193998048122485e-05, 2398),\n",
       " (7.19248210685963e-05, 5823),\n",
       " (7.184871478959352e-05, 5460),\n",
       " (7.175587439827423e-05, 8361),\n",
       " (7.15518903286228e-05, 517),\n",
       " (7.14611853930786e-05, 6288),\n",
       " (7.138414746939435e-05, 5051),\n",
       " (7.118011383067837e-05, 8041),\n",
       " (7.045924817509758e-05, 4915),\n",
       " (7.013532435424208e-05, 6798),\n",
       " (6.971596516812193e-05, 4731),\n",
       " (6.961676381984435e-05, 3409),\n",
       " (6.937524497662227e-05, 4638),\n",
       " (6.897980300350129e-05, 6796),\n",
       " (6.852567252658401e-05, 310),\n",
       " (6.836077963453007e-05, 7143),\n",
       " (6.775497957683866e-05, 1120),\n",
       " (6.766878290083633e-05, 1988),\n",
       " (6.760913221039837e-05, 4030),\n",
       " (6.704936875990827e-05, 3812),\n",
       " (6.689812000298885e-05, 7493),\n",
       " (6.68157728225374e-05, 1253),\n",
       " (6.680070316294895e-05, 4533),\n",
       " (6.556408321311886e-05, 2592),\n",
       " (6.55322362307451e-05, 8013),\n",
       " (6.544793616625549e-05, 5779),\n",
       " (6.533059858080431e-05, 5391),\n",
       " (6.458559388629192e-05, 3903),\n",
       " (6.41694903789695e-05, 5552),\n",
       " (6.392862753017805e-05, 5511),\n",
       " (6.382024669236476e-05, 7465),\n",
       " (6.322857496158454e-05, 2095),\n",
       " (6.308052021606192e-05, 267),\n",
       " (6.292994057755163e-05, 1855),\n",
       " (6.291723716432572e-05, 7341),\n",
       " (6.291094678151528e-05, 4437),\n",
       " (6.2899023643082e-05, 8269),\n",
       " (6.258821297421478e-05, 1446),\n",
       " (6.24565468491793e-05, 7531),\n",
       " (6.173027038916495e-05, 609),\n",
       " (6.171624367559839e-05, 1422),\n",
       " (6.12421235186674e-05, 6536),\n",
       " (6.109130688494038e-05, 3342),\n",
       " (6.091799236106502e-05, 3926),\n",
       " (6.0887568765580615e-05, 7609),\n",
       " (6.088553320374115e-05, 6863),\n",
       " (6.082556260935141e-05, 866),\n",
       " (6.006677057703734e-05, 3820),\n",
       " (6.004055316585404e-05, 1369),\n",
       " (5.995828497521203e-05, 6004),\n",
       " (5.986643563360437e-05, 6338),\n",
       " (5.945171135471809e-05, 3243),\n",
       " (5.9332687158639716e-05, 6344),\n",
       " (5.9213220296243125e-05, 3481),\n",
       " (5.905791594676105e-05, 627),\n",
       " (5.877100768367412e-05, 11),\n",
       " (5.861223422340901e-05, 4590),\n",
       " (5.860060603256675e-05, 5640),\n",
       " (5.846131995396728e-05, 1796),\n",
       " (5.8327475140816766e-05, 4230),\n",
       " (5.831666729368606e-05, 8159),\n",
       " (5.7943105091460244e-05, 2160),\n",
       " (5.793537211212097e-05, 3081),\n",
       " (5.791706924663521e-05, 1653),\n",
       " (5.790250616717484e-05, 466),\n",
       " (5.789877927769151e-05, 8193),\n",
       " (5.759107860440626e-05, 4572),\n",
       " (5.754972521051796e-05, 355),\n",
       " (5.7331575917334686e-05, 3367),\n",
       " (5.7223681782779664e-05, 7466),\n",
       " (5.695219728785757e-05, 3166),\n",
       " (5.680327945343065e-05, 7515),\n",
       " (5.679508424978565e-05, 898),\n",
       " (5.6740542225353215e-05, 1186),\n",
       " (5.6543377346008624e-05, 6104),\n",
       " (5.651561205369407e-05, 7884),\n",
       " (5.633494195763777e-05, 1181),\n",
       " (5.6222372026147706e-05, 3265),\n",
       " (5.603298175578995e-05, 6131),\n",
       " (5.59475496637495e-05, 4716),\n",
       " (5.5843335779437506e-05, 5924),\n",
       " (5.561275972950503e-05, 4529),\n",
       " (5.525199997356293e-05, 6622),\n",
       " (5.5242222166606276e-05, 7935),\n",
       " (5.478530222486808e-05, 3596),\n",
       " (5.428691711375704e-05, 6234),\n",
       " (5.403897310726876e-05, 8218),\n",
       " (5.384822689318076e-05, 1427),\n",
       " (5.381690579870567e-05, 3115),\n",
       " (5.376518288290326e-05, 7419),\n",
       " (5.369141480956206e-05, 5235),\n",
       " (5.3621305801099335e-05, 2536),\n",
       " (5.3575068103868805e-05, 802),\n",
       " (5.3568215477662907e-05, 7081),\n",
       " (5.3490315886613075e-05, 6432),\n",
       " (5.344283118268252e-05, 4226),\n",
       " (5.340018983908713e-05, 2228),\n",
       " (5.339268495736656e-05, 1413),\n",
       " (5.3370842534128963e-05, 7040),\n",
       " (5.3339277089467655e-05, 7841),\n",
       " (5.333881476250328e-05, 4879),\n",
       " (5.333279852031531e-05, 7761),\n",
       " (5.319693445685882e-05, 1626),\n",
       " (5.311643699074844e-05, 2995),\n",
       " (5.3059242134372795e-05, 3492),\n",
       " (5.292650516183054e-05, 5757),\n",
       " (5.289839046868254e-05, 2977),\n",
       " (5.27241110226537e-05, 3878),\n",
       " (5.266354082578311e-05, 1307),\n",
       " (5.256625696010543e-05, 3989),\n",
       " (5.245629922738864e-05, 7648),\n",
       " (5.19755851936175e-05, 1315),\n",
       " (5.196863444587661e-05, 5662),\n",
       " (5.1962644662513965e-05, 764),\n",
       " (5.19262287326631e-05, 5156),\n",
       " (5.178723620334637e-05, 5453),\n",
       " (5.1781601554609224e-05, 7046),\n",
       " (5.17370094928801e-05, 6209),\n",
       " (5.171779173530196e-05, 4115),\n",
       " (5.1645612531393294e-05, 290),\n",
       " (5.138040275242301e-05, 7615),\n",
       " (5.131004842042671e-05, 4808),\n",
       " (5.122032116733484e-05, 1306),\n",
       " (5.099730322329714e-05, 1165),\n",
       " (5.0804477540827435e-05, 1929),\n",
       " (5.0573624557652996e-05, 6837),\n",
       " (5.0554058118379545e-05, 714),\n",
       " (5.0478839858602837e-05, 1938),\n",
       " (5.033523084447808e-05, 4094),\n",
       " (5.026037596131929e-05, 6641),\n",
       " (5.01620295850712e-05, 5637),\n",
       " (5.004006469459643e-05, 3068),\n",
       " (4.995838021656068e-05, 4706),\n",
       " (4.9927438371136305e-05, 6735),\n",
       " (4.9862408087104193e-05, 4420),\n",
       " (4.9855233719030494e-05, 4805),\n",
       " (4.9845210461942634e-05, 7255),\n",
       " (4.978725885639655e-05, 166),\n",
       " (4.978545362022482e-05, 7874),\n",
       " (4.96946324272536e-05, 2084),\n",
       " (4.959360113287762e-05, 2082),\n",
       " (4.9569465150324284e-05, 66),\n",
       " (4.948410294692829e-05, 4774),\n",
       " (4.938723531002388e-05, 2742),\n",
       " (4.934280477728657e-05, 787),\n",
       " (4.9329247914670124e-05, 1),\n",
       " (4.924982628206979e-05, 2258),\n",
       " (4.923549212710008e-05, 1041),\n",
       " (4.908096429328764e-05, 1127),\n",
       " (4.907223649084451e-05, 4606),\n",
       " (4.894612647929513e-05, 8317),\n",
       " (4.892984167426006e-05, 5834),\n",
       " (4.891893998620185e-05, 6613),\n",
       " (4.891893998620185e-05, 5656),\n",
       " (4.890185933822722e-05, 602),\n",
       " (4.8691999148256554e-05, 8110),\n",
       " (4.836883529288844e-05, 8043),\n",
       " (4.8317670663636014e-05, 4746),\n",
       " (4.816914103773766e-05, 3062),\n",
       " (4.8165020455385226e-05, 3700),\n",
       " (4.7946621392420285e-05, 2109),\n",
       " (4.7939393985945725e-05, 5288),\n",
       " (4.75702485174133e-05, 1055),\n",
       " (4.750897420208694e-05, 1025),\n",
       " (4.729251736522725e-05, 60),\n",
       " (4.7288872024962234e-05, 5948),\n",
       " (4.724019442616632e-05, 2841),\n",
       " (4.720008533596514e-05, 3234),\n",
       " (4.6833146747927805e-05, 1631),\n",
       " (4.654746893719136e-05, 5499),\n",
       " (4.653559654651597e-05, 7778),\n",
       " (4.6512974684383955e-05, 4347),\n",
       " (4.650841748616406e-05, 2862),\n",
       " (4.6282129073323266e-05, 7708),\n",
       " (4.6258049104055366e-05, 1110),\n",
       " (4.61160488841178e-05, 1587),\n",
       " ...]"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(zip(rf_model.feature_importances_, X_train.columns), reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 1.0, Recall: 0.623, Accuracy: 0.9533632286995516\n"
     ]
    }
   ],
   "source": [
    "y_pred = rf_model.predict(X_test)\n",
    "precision, recall, fscore, support = score(y_test, y_pred, pos_label='spam', average='binary')\n",
    "print('Precision: {}, Recall: {}, Accuracy: {}'.format(round(precision, 3), round(recall, 3), (y_pred==y_test).sum() / len(y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explore Random Forest model with grid-search\n",
    "#### Build your own grid-search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_RF(n_est, depth):\n",
    "    rf = RandomForestClassifier(n_estimators=n_est, max_depth=depth, n_jobs=-1)\n",
    "    rf_model = rf.fit(X_train, y_train)\n",
    "    y_pred = rf_model.predict(X_test)\n",
    "    precision, recall, fscore, support = score(y_test, y_pred, pos_label='spam', average='binary')\n",
    "    print('Est: {} / Depth: {} ---- Precision: {}, Recall: {}, Accuracy: {}'.\n",
    "          format(n_est, depth, round(precision, 3), round(recall, 3), round((y_pred==y_test).sum() / len(y_test), 3)))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Est: 10 / Depth: 10 ---- Precision: 1.0, Recall: 0.348, Accuracy: 0.919\n",
      "Est: 10 / Depth: 20 ---- Precision: 1.0, Recall: 0.623, Accuracy: 0.953\n",
      "Est: 10 / Depth: 30 ---- Precision: 0.991, Recall: 0.768, Accuracy: 0.97\n",
      "Est: 10 / Depth: None ---- Precision: 0.973, Recall: 0.797, Accuracy: 0.972\n",
      "Est: 50 / Depth: 10 ---- Precision: 1.0, Recall: 0.333, Accuracy: 0.917\n",
      "Est: 50 / Depth: 20 ---- Precision: 1.0, Recall: 0.667, Accuracy: 0.959\n",
      "Est: 50 / Depth: 30 ---- Precision: 1.0, Recall: 0.761, Accuracy: 0.97\n",
      "Est: 50 / Depth: None ---- Precision: 1.0, Recall: 0.797, Accuracy: 0.975\n",
      "Est: 100 / Depth: 10 ---- Precision: 1.0, Recall: 0.29, Accuracy: 0.912\n",
      "Est: 100 / Depth: 20 ---- Precision: 1.0, Recall: 0.587, Accuracy: 0.949\n",
      "Est: 100 / Depth: 30 ---- Precision: 1.0, Recall: 0.739, Accuracy: 0.968\n",
      "Est: 100 / Depth: None ---- Precision: 1.0, Recall: 0.862, Accuracy: 0.983\n"
     ]
    }
   ],
   "source": [
    "for n_est in [10, 50, 100]:\n",
    "    for depth in [10, 20, 30, None]:\n",
    "        train_RF(n_est, depth)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate Random Forest model performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      body_len  punct%    0    1    2    3    4    5    6    7  ...  8376  \\\n",
      "0           97    14.4  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   0.0   \n",
      "1           27    33.3  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   0.0   \n",
      "2          131     6.9  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   0.0   \n",
      "3           42    21.4  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   0.0   \n",
      "4           54    13.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   0.0   \n",
      "...        ...     ...  ...  ...  ...  ...  ...  ...  ...  ...  ...   ...   \n",
      "5568       137     9.5  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   0.0   \n",
      "5569        33    15.2  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   0.0   \n",
      "5570        53    22.6  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   0.0   \n",
      "5571       103     3.9  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   0.0   \n",
      "5572        24    16.7  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   0.0   \n",
      "\n",
      "      8377  8378  8379  8380  8381  8382  8383  8384  8385  \n",
      "0      0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
      "1      0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
      "2      0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
      "3      0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
      "4      0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
      "...    ...   ...   ...   ...   ...   ...   ...   ...   ...  \n",
      "5568   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
      "5569   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
      "5570   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
      "5571   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
      "5572   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
      "\n",
      "[5573 rows x 8388 columns]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>body_len</th>\n",
       "      <th>punct%</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>...</th>\n",
       "      <th>8376</th>\n",
       "      <th>8377</th>\n",
       "      <th>8378</th>\n",
       "      <th>8379</th>\n",
       "      <th>8380</th>\n",
       "      <th>8381</th>\n",
       "      <th>8382</th>\n",
       "      <th>8383</th>\n",
       "      <th>8384</th>\n",
       "      <th>8385</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>97</td>\n",
       "      <td>14.4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>27</td>\n",
       "      <td>33.3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>131</td>\n",
       "      <td>6.9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>42</td>\n",
       "      <td>21.4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>54</td>\n",
       "      <td>13.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 8388 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   body_len  punct%  0  1  2  3  4  5  6  7  ...  8376  8377  8378  8379  \\\n",
       "0        97    14.4  0  0  0  0  0  0  0  0  ...     0     0     0     0   \n",
       "1        27    33.3  0  0  0  0  0  0  0  0  ...     0     0     0     0   \n",
       "2       131     6.9  0  0  0  0  0  0  0  0  ...     0     0     0     0   \n",
       "3        42    21.4  0  0  0  0  0  0  0  0  ...     0     0     0     0   \n",
       "4        54    13.0  0  0  0  0  0  0  0  0  ...     0     0     0     0   \n",
       "\n",
       "   8380  8381  8382  8383  8384  8385  \n",
       "0     0     0     0     0     0     0  \n",
       "1     0     0     0     0     0     0  \n",
       "2     0     0     0     0     0     0  \n",
       "3     0     0     0     0     0     0  \n",
       "4     0     0     0     0     0     0  \n",
       "\n",
       "[5 rows x 8388 columns]"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# some pre-processing\n",
    "# TF-IDF\n",
    "tfidf_vect = TfidfVectorizer(analyzer=clean_text)\n",
    "X_tfidf = tfidf_vect.fit_transform(data['body_text'])\n",
    "X_tfidf_feat = pd.concat([data['body_len'], data['punct%'], pd.DataFrame(X_tfidf.toarray())], axis=1)\n",
    "\n",
    "# CountVectorizer\n",
    "count_vect = CountVectorizer(analyzer=clean_text)\n",
    "X_count = count_vect.fit_transform(data['body_text'])\n",
    "X_count_feat = pd.concat([data['body_len'], data['punct%'], pd.DataFrame(X_count.toarray())], axis=1)\n",
    "\n",
    "print(X_tfidf_feat)\n",
    "X_count_feat.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_max_depth</th>\n",
       "      <th>param_n_estimators</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>36.978561</td>\n",
       "      <td>0.738500</td>\n",
       "      <td>0.627119</td>\n",
       "      <td>0.138091</td>\n",
       "      <td>90</td>\n",
       "      <td>150</td>\n",
       "      <td>{'max_depth': 90, 'n_estimators': 150}</td>\n",
       "      <td>0.977578</td>\n",
       "      <td>0.977578</td>\n",
       "      <td>0.976682</td>\n",
       "      <td>0.970377</td>\n",
       "      <td>0.976661</td>\n",
       "      <td>0.975775</td>\n",
       "      <td>0.002729</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>38.360199</td>\n",
       "      <td>1.648807</td>\n",
       "      <td>0.505153</td>\n",
       "      <td>0.074082</td>\n",
       "      <td>None</td>\n",
       "      <td>150</td>\n",
       "      <td>{'max_depth': None, 'n_estimators': 150}</td>\n",
       "      <td>0.977578</td>\n",
       "      <td>0.974888</td>\n",
       "      <td>0.976682</td>\n",
       "      <td>0.970377</td>\n",
       "      <td>0.978456</td>\n",
       "      <td>0.975596</td>\n",
       "      <td>0.002865</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>71.629715</td>\n",
       "      <td>1.363582</td>\n",
       "      <td>0.750297</td>\n",
       "      <td>0.020217</td>\n",
       "      <td>90</td>\n",
       "      <td>300</td>\n",
       "      <td>{'max_depth': 90, 'n_estimators': 300}</td>\n",
       "      <td>0.978475</td>\n",
       "      <td>0.975785</td>\n",
       "      <td>0.977578</td>\n",
       "      <td>0.969479</td>\n",
       "      <td>0.976661</td>\n",
       "      <td>0.975596</td>\n",
       "      <td>0.003188</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>62.179225</td>\n",
       "      <td>1.043739</td>\n",
       "      <td>0.433688</td>\n",
       "      <td>0.079459</td>\n",
       "      <td>None</td>\n",
       "      <td>300</td>\n",
       "      <td>{'max_depth': None, 'n_estimators': 300}</td>\n",
       "      <td>0.977578</td>\n",
       "      <td>0.975785</td>\n",
       "      <td>0.976682</td>\n",
       "      <td>0.969479</td>\n",
       "      <td>0.974865</td>\n",
       "      <td>0.974878</td>\n",
       "      <td>0.002847</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>32.910108</td>\n",
       "      <td>0.679701</td>\n",
       "      <td>0.584578</td>\n",
       "      <td>0.078852</td>\n",
       "      <td>60</td>\n",
       "      <td>150</td>\n",
       "      <td>{'max_depth': 60, 'n_estimators': 150}</td>\n",
       "      <td>0.974888</td>\n",
       "      <td>0.974888</td>\n",
       "      <td>0.977578</td>\n",
       "      <td>0.969479</td>\n",
       "      <td>0.976661</td>\n",
       "      <td>0.974699</td>\n",
       "      <td>0.002809</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "7       36.978561      0.738500         0.627119        0.138091   \n",
       "10      38.360199      1.648807         0.505153        0.074082   \n",
       "8       71.629715      1.363582         0.750297        0.020217   \n",
       "11      62.179225      1.043739         0.433688        0.079459   \n",
       "4       32.910108      0.679701         0.584578        0.078852   \n",
       "\n",
       "   param_max_depth param_n_estimators  \\\n",
       "7               90                150   \n",
       "10            None                150   \n",
       "8               90                300   \n",
       "11            None                300   \n",
       "4               60                150   \n",
       "\n",
       "                                      params  split0_test_score  \\\n",
       "7     {'max_depth': 90, 'n_estimators': 150}           0.977578   \n",
       "10  {'max_depth': None, 'n_estimators': 150}           0.977578   \n",
       "8     {'max_depth': 90, 'n_estimators': 300}           0.978475   \n",
       "11  {'max_depth': None, 'n_estimators': 300}           0.977578   \n",
       "4     {'max_depth': 60, 'n_estimators': 150}           0.974888   \n",
       "\n",
       "    split1_test_score  split2_test_score  split3_test_score  \\\n",
       "7            0.977578           0.976682           0.970377   \n",
       "10           0.974888           0.976682           0.970377   \n",
       "8            0.975785           0.977578           0.969479   \n",
       "11           0.975785           0.976682           0.969479   \n",
       "4            0.974888           0.977578           0.969479   \n",
       "\n",
       "    split4_test_score  mean_test_score  std_test_score  rank_test_score  \n",
       "7            0.976661         0.975775        0.002729                1  \n",
       "10           0.978456         0.975596        0.002865                2  \n",
       "8            0.976661         0.975596        0.003188                3  \n",
       "11           0.974865         0.974878        0.002847                4  \n",
       "4            0.976661         0.974699        0.002809                5  "
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf = RandomForestClassifier()\n",
    "param ={'n_estimators': [10, 150, 300],\n",
    "        'max_depth': [30, 60, 90, None]}\n",
    "gs = GridSearchCV(rf, param, cv=5, n_jobs=-1)\n",
    "gs_fit = gs.fit(X_tfidf_feat, data['label'])\n",
    "pd.DataFrame(gs_fit.cv_results_).sort_values('mean_test_score', ascending=False)[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\Gaurav\\anaconda3\\lib\\site-packages\\joblib\\externals\\loky\\process_executor.py:688: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_max_depth</th>\n",
       "      <th>param_n_estimators</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>37.536535</td>\n",
       "      <td>0.490694</td>\n",
       "      <td>0.673007</td>\n",
       "      <td>0.168374</td>\n",
       "      <td>90</td>\n",
       "      <td>150</td>\n",
       "      <td>{'max_depth': 90, 'n_estimators': 150}</td>\n",
       "      <td>0.978475</td>\n",
       "      <td>0.974888</td>\n",
       "      <td>0.976682</td>\n",
       "      <td>0.971275</td>\n",
       "      <td>0.975763</td>\n",
       "      <td>0.975417</td>\n",
       "      <td>0.002388</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>60.977668</td>\n",
       "      <td>0.884955</td>\n",
       "      <td>0.401941</td>\n",
       "      <td>0.055645</td>\n",
       "      <td>None</td>\n",
       "      <td>300</td>\n",
       "      <td>{'max_depth': None, 'n_estimators': 300}</td>\n",
       "      <td>0.976682</td>\n",
       "      <td>0.975785</td>\n",
       "      <td>0.975785</td>\n",
       "      <td>0.970377</td>\n",
       "      <td>0.974865</td>\n",
       "      <td>0.974699</td>\n",
       "      <td>0.002236</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>36.863991</td>\n",
       "      <td>1.200710</td>\n",
       "      <td>0.466119</td>\n",
       "      <td>0.103793</td>\n",
       "      <td>None</td>\n",
       "      <td>150</td>\n",
       "      <td>{'max_depth': None, 'n_estimators': 150}</td>\n",
       "      <td>0.978475</td>\n",
       "      <td>0.975785</td>\n",
       "      <td>0.974888</td>\n",
       "      <td>0.968582</td>\n",
       "      <td>0.975763</td>\n",
       "      <td>0.974699</td>\n",
       "      <td>0.003287</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>71.975272</td>\n",
       "      <td>1.251871</td>\n",
       "      <td>0.854194</td>\n",
       "      <td>0.045987</td>\n",
       "      <td>90</td>\n",
       "      <td>300</td>\n",
       "      <td>{'max_depth': 90, 'n_estimators': 300}</td>\n",
       "      <td>0.975785</td>\n",
       "      <td>0.975785</td>\n",
       "      <td>0.975785</td>\n",
       "      <td>0.969479</td>\n",
       "      <td>0.975763</td>\n",
       "      <td>0.974519</td>\n",
       "      <td>0.002520</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.465225</td>\n",
       "      <td>0.296444</td>\n",
       "      <td>0.326072</td>\n",
       "      <td>0.034061</td>\n",
       "      <td>60</td>\n",
       "      <td>10</td>\n",
       "      <td>{'max_depth': 60, 'n_estimators': 10}</td>\n",
       "      <td>0.977578</td>\n",
       "      <td>0.973094</td>\n",
       "      <td>0.969507</td>\n",
       "      <td>0.973070</td>\n",
       "      <td>0.973070</td>\n",
       "      <td>0.973264</td>\n",
       "      <td>0.002563</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "7       37.536535      0.490694         0.673007        0.168374   \n",
       "11      60.977668      0.884955         0.401941        0.055645   \n",
       "10      36.863991      1.200710         0.466119        0.103793   \n",
       "8       71.975272      1.251871         0.854194        0.045987   \n",
       "3        5.465225      0.296444         0.326072        0.034061   \n",
       "\n",
       "   param_max_depth param_n_estimators  \\\n",
       "7               90                150   \n",
       "11            None                300   \n",
       "10            None                150   \n",
       "8               90                300   \n",
       "3               60                 10   \n",
       "\n",
       "                                      params  split0_test_score  \\\n",
       "7     {'max_depth': 90, 'n_estimators': 150}           0.978475   \n",
       "11  {'max_depth': None, 'n_estimators': 300}           0.976682   \n",
       "10  {'max_depth': None, 'n_estimators': 150}           0.978475   \n",
       "8     {'max_depth': 90, 'n_estimators': 300}           0.975785   \n",
       "3      {'max_depth': 60, 'n_estimators': 10}           0.977578   \n",
       "\n",
       "    split1_test_score  split2_test_score  split3_test_score  \\\n",
       "7            0.974888           0.976682           0.971275   \n",
       "11           0.975785           0.975785           0.970377   \n",
       "10           0.975785           0.974888           0.968582   \n",
       "8            0.975785           0.975785           0.969479   \n",
       "3            0.973094           0.969507           0.973070   \n",
       "\n",
       "    split4_test_score  mean_test_score  std_test_score  rank_test_score  \n",
       "7            0.975763         0.975417        0.002388                1  \n",
       "11           0.974865         0.974699        0.002236                2  \n",
       "10           0.975763         0.974699        0.003287                3  \n",
       "8            0.975763         0.974519        0.002520                4  \n",
       "3            0.973070         0.973264        0.002563                5  "
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf = RandomForestClassifier()\n",
    "param ={'n_estimators': [10, 150, 300],\n",
    "        'max_depth': [30, 60, 90, None]}\n",
    "gs = GridSearchCV(rf, param, cv=5, n_jobs=-1)\n",
    "gs_fit = gs.fit(X_count_feat, data['label'])\n",
    "pd.DataFrame(gs_fit.cv_results_).sort_values('mean_test_score', ascending=False)[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction to Gradient boosting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explore GradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_GB(est, max_depth, lr):\n",
    "    gb = GradientBoostingClassifier(n_estimators=n_est, max_depth=max_depth, learning_rate=lr)\n",
    "    gb_model = gb.fit(X_train, y_train)\n",
    "    y_pred = gb_model.predict(X_test)\n",
    "    precision, recall, fscore, support = score(y_test, y_pred, pos_label='spam', average='binary')\n",
    "    print('Est: {} / Depth: {} / LR: {} ---- Precision: {}, Recall: {}, Accuracy: {}'.\n",
    "          format(n_est, max_depth, lr, round(precision, 3), round(recall, 3), round((y_pred==y_test).sum() / len(y_test), 3)))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Est: 50 / Depth: 3 / LR: 0.01 ---- Precision: 1.0, Recall: 0.077, Accuracy: 0.892\n",
      "Est: 50 / Depth: 3 / LR: 0.1 ---- Precision: 0.964, Recall: 0.815, Accuracy: 0.975\n",
      "Est: 50 / Depth: 3 / LR: 1 ---- Precision: 0.829, Recall: 0.785, Accuracy: 0.956\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\Gaurav\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Est: 50 / Depth: 7 / LR: 0.01 ---- Precision: 0.0, Recall: 0.0, Accuracy: 0.883\n",
      "Est: 50 / Depth: 7 / LR: 0.1 ---- Precision: 0.935, Recall: 0.892, Accuracy: 0.98\n",
      "Est: 50 / Depth: 7 / LR: 1 ---- Precision: 0.85, Recall: 0.831, Accuracy: 0.963\n",
      "Est: 50 / Depth: 11 / LR: 0.01 ---- Precision: 1.0, Recall: 0.015, Accuracy: 0.885\n",
      "Est: 50 / Depth: 11 / LR: 0.1 ---- Precision: 0.923, Recall: 0.923, Accuracy: 0.982\n",
      "Est: 50 / Depth: 11 / LR: 1 ---- Precision: 0.88, Recall: 0.9, Accuracy: 0.974\n",
      "Est: 50 / Depth: 15 / LR: 0.01 ---- Precision: 0.667, Recall: 0.015, Accuracy: 0.884\n",
      "Est: 50 / Depth: 15 / LR: 0.1 ---- Precision: 0.929, Recall: 0.908, Accuracy: 0.981\n",
      "Est: 50 / Depth: 15 / LR: 1 ---- Precision: 0.901, Recall: 0.908, Accuracy: 0.978\n",
      "Est: 100 / Depth: 3 / LR: 0.01 ---- Precision: 1.0, Recall: 0.485, Accuracy: 0.94\n",
      "Est: 100 / Depth: 3 / LR: 0.1 ---- Precision: 0.941, Recall: 0.862, Accuracy: 0.978\n",
      "Est: 100 / Depth: 3 / LR: 1 ---- Precision: 0.856, Recall: 0.823, Accuracy: 0.963\n",
      "Est: 100 / Depth: 7 / LR: 0.01 ---- Precision: 0.948, Recall: 0.708, Accuracy: 0.961\n",
      "Est: 100 / Depth: 7 / LR: 0.1 ---- Precision: 0.937, Recall: 0.908, Accuracy: 0.982\n",
      "Est: 100 / Depth: 7 / LR: 1 ---- Precision: 0.832, Recall: 0.838, Accuracy: 0.961\n",
      "Est: 100 / Depth: 11 / LR: 0.01 ---- Precision: 0.955, Recall: 0.808, Accuracy: 0.973\n",
      "Est: 100 / Depth: 11 / LR: 0.1 ---- Precision: 0.945, Recall: 0.931, Accuracy: 0.986\n",
      "Est: 100 / Depth: 11 / LR: 1 ---- Precision: 0.895, Recall: 0.915, Accuracy: 0.978\n",
      "Est: 100 / Depth: 15 / LR: 0.01 ---- Precision: 0.938, Recall: 0.815, Accuracy: 0.972\n",
      "Est: 100 / Depth: 15 / LR: 0.1 ---- Precision: 0.938, Recall: 0.923, Accuracy: 0.984\n",
      "Est: 100 / Depth: 15 / LR: 1 ---- Precision: 0.937, Recall: 0.915, Accuracy: 0.983\n",
      "Est: 150 / Depth: 3 / LR: 0.01 ---- Precision: 0.964, Recall: 0.615, Accuracy: 0.952\n",
      "Est: 150 / Depth: 3 / LR: 0.1 ---- Precision: 0.942, Recall: 0.869, Accuracy: 0.978\n",
      "Est: 150 / Depth: 3 / LR: 1 ---- Precision: 0.846, Recall: 0.846, Accuracy: 0.964\n",
      "Est: 150 / Depth: 7 / LR: 0.01 ---- Precision: 0.935, Recall: 0.777, Accuracy: 0.968\n",
      "Est: 150 / Depth: 7 / LR: 0.1 ---- Precision: 0.944, Recall: 0.915, Accuracy: 0.984\n",
      "Est: 150 / Depth: 7 / LR: 1 ---- Precision: 0.889, Recall: 0.862, Accuracy: 0.971\n",
      "Est: 150 / Depth: 11 / LR: 0.01 ---- Precision: 0.947, Recall: 0.823, Accuracy: 0.974\n",
      "Est: 150 / Depth: 11 / LR: 0.1 ---- Precision: 0.923, Recall: 0.923, Accuracy: 0.982\n",
      "Est: 150 / Depth: 11 / LR: 1 ---- Precision: 0.899, Recall: 0.892, Accuracy: 0.976\n",
      "Est: 150 / Depth: 15 / LR: 0.01 ---- Precision: 0.933, Recall: 0.854, Accuracy: 0.976\n",
      "Est: 150 / Depth: 15 / LR: 0.1 ---- Precision: 0.93, Recall: 0.923, Accuracy: 0.983\n"
     ]
    }
   ],
   "source": [
    "for n_est in [50, 100, 150]:\n",
    "    for max_depth in [3, 7, 11, 15]:\n",
    "        for lr in [0.01, 0.1, 1]:\n",
    "            train_GB(n_est, max_depth, lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate Gradient Boosting with GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_learning_rate</th>\n",
       "      <th>param_max_depth</th>\n",
       "      <th>param_n_estimators</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>495.455216</td>\n",
       "      <td>6.217503</td>\n",
       "      <td>0.159341</td>\n",
       "      <td>0.015314</td>\n",
       "      <td>0.1</td>\n",
       "      <td>15</td>\n",
       "      <td>150</td>\n",
       "      <td>{'learning_rate': 0.1, 'max_depth': 15, 'n_estimators': 150}</td>\n",
       "      <td>0.970404</td>\n",
       "      <td>0.982063</td>\n",
       "      <td>0.974888</td>\n",
       "      <td>0.973968</td>\n",
       "      <td>0.973070</td>\n",
       "      <td>0.974878</td>\n",
       "      <td>0.003892</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2134.972430</td>\n",
       "      <td>21.418881</td>\n",
       "      <td>0.286460</td>\n",
       "      <td>0.011101</td>\n",
       "      <td>0.1</td>\n",
       "      <td>11</td>\n",
       "      <td>150</td>\n",
       "      <td>{'learning_rate': 0.1, 'max_depth': 11, 'n_estimators': 150}</td>\n",
       "      <td>0.973094</td>\n",
       "      <td>0.982063</td>\n",
       "      <td>0.974888</td>\n",
       "      <td>0.971275</td>\n",
       "      <td>0.971275</td>\n",
       "      <td>0.974519</td>\n",
       "      <td>0.004003</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>373.022921</td>\n",
       "      <td>20.131748</td>\n",
       "      <td>0.393668</td>\n",
       "      <td>0.053233</td>\n",
       "      <td>0.1</td>\n",
       "      <td>7</td>\n",
       "      <td>150</td>\n",
       "      <td>{'learning_rate': 0.1, 'max_depth': 7, 'n_estimators': 150}</td>\n",
       "      <td>0.974888</td>\n",
       "      <td>0.976682</td>\n",
       "      <td>0.973094</td>\n",
       "      <td>0.976661</td>\n",
       "      <td>0.968582</td>\n",
       "      <td>0.973981</td>\n",
       "      <td>0.003008</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1040.436149</td>\n",
       "      <td>811.846202</td>\n",
       "      <td>0.301794</td>\n",
       "      <td>0.057283</td>\n",
       "      <td>0.1</td>\n",
       "      <td>11</td>\n",
       "      <td>100</td>\n",
       "      <td>{'learning_rate': 0.1, 'max_depth': 11, 'n_estimators': 100}</td>\n",
       "      <td>0.970404</td>\n",
       "      <td>0.980269</td>\n",
       "      <td>0.976682</td>\n",
       "      <td>0.972172</td>\n",
       "      <td>0.970377</td>\n",
       "      <td>0.973981</td>\n",
       "      <td>0.003896</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>693.663395</td>\n",
       "      <td>674.375390</td>\n",
       "      <td>0.269183</td>\n",
       "      <td>0.027125</td>\n",
       "      <td>0.1</td>\n",
       "      <td>15</td>\n",
       "      <td>100</td>\n",
       "      <td>{'learning_rate': 0.1, 'max_depth': 15, 'n_estimators': 100}</td>\n",
       "      <td>0.970404</td>\n",
       "      <td>0.982063</td>\n",
       "      <td>0.972197</td>\n",
       "      <td>0.971275</td>\n",
       "      <td>0.973070</td>\n",
       "      <td>0.973802</td>\n",
       "      <td>0.004226</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "5     495.455216      6.217503         0.159341        0.015314   \n",
       "3    2134.972430     21.418881         0.286460        0.011101   \n",
       "1     373.022921     20.131748         0.393668        0.053233   \n",
       "2    1040.436149    811.846202         0.301794        0.057283   \n",
       "4     693.663395    674.375390         0.269183        0.027125   \n",
       "\n",
       "  param_learning_rate param_max_depth param_n_estimators  \\\n",
       "5                 0.1              15                150   \n",
       "3                 0.1              11                150   \n",
       "1                 0.1               7                150   \n",
       "2                 0.1              11                100   \n",
       "4                 0.1              15                100   \n",
       "\n",
       "                                                         params  \\\n",
       "5  {'learning_rate': 0.1, 'max_depth': 15, 'n_estimators': 150}   \n",
       "3  {'learning_rate': 0.1, 'max_depth': 11, 'n_estimators': 150}   \n",
       "1   {'learning_rate': 0.1, 'max_depth': 7, 'n_estimators': 150}   \n",
       "2  {'learning_rate': 0.1, 'max_depth': 11, 'n_estimators': 100}   \n",
       "4  {'learning_rate': 0.1, 'max_depth': 15, 'n_estimators': 100}   \n",
       "\n",
       "   split0_test_score  split1_test_score  split2_test_score  split3_test_score  \\\n",
       "5           0.970404           0.982063           0.974888           0.973968   \n",
       "3           0.973094           0.982063           0.974888           0.971275   \n",
       "1           0.974888           0.976682           0.973094           0.976661   \n",
       "2           0.970404           0.980269           0.976682           0.972172   \n",
       "4           0.970404           0.982063           0.972197           0.971275   \n",
       "\n",
       "   split4_test_score  mean_test_score  std_test_score  rank_test_score  \n",
       "5           0.973070         0.974878        0.003892                1  \n",
       "3           0.971275         0.974519        0.004003                2  \n",
       "1           0.968582         0.973981        0.003008                3  \n",
       "2           0.970377         0.973981        0.003896                4  \n",
       "4           0.973070         0.973802        0.004226                5  "
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gb = GradientBoostingClassifier()\n",
    "param ={'n_estimators': [100, 150],\n",
    "        'max_depth': [7, 11, 15],\n",
    "        'learning_rate': [0.1]}\n",
    "gs = GridSearchCV(gb, param, cv=5, n_jobs=-1)\n",
    "cv_fit = gs.fit(X_tfidf_feat, data['label'])\n",
    "pd.DataFrame(cv_fit.cv_results_).sort_values('mean_test_score', ascending=False)[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_learning_rate</th>\n",
       "      <th>param_max_depth</th>\n",
       "      <th>param_n_estimators</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>495.324935</td>\n",
       "      <td>2.785917</td>\n",
       "      <td>0.190579</td>\n",
       "      <td>0.043517</td>\n",
       "      <td>0.1</td>\n",
       "      <td>15</td>\n",
       "      <td>150</td>\n",
       "      <td>{'learning_rate': 0.1, 'max_depth': 15, 'n_estimators': 150}</td>\n",
       "      <td>0.973991</td>\n",
       "      <td>0.979372</td>\n",
       "      <td>0.973094</td>\n",
       "      <td>0.973070</td>\n",
       "      <td>0.970377</td>\n",
       "      <td>0.973981</td>\n",
       "      <td>0.002955</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2620.852999</td>\n",
       "      <td>3.585602</td>\n",
       "      <td>0.303053</td>\n",
       "      <td>0.037751</td>\n",
       "      <td>0.1</td>\n",
       "      <td>11</td>\n",
       "      <td>150</td>\n",
       "      <td>{'learning_rate': 0.1, 'max_depth': 11, 'n_estimators': 150}</td>\n",
       "      <td>0.973991</td>\n",
       "      <td>0.981166</td>\n",
       "      <td>0.971300</td>\n",
       "      <td>0.973070</td>\n",
       "      <td>0.968582</td>\n",
       "      <td>0.973622</td>\n",
       "      <td>0.004199</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1711.796690</td>\n",
       "      <td>1165.469866</td>\n",
       "      <td>0.287431</td>\n",
       "      <td>0.032164</td>\n",
       "      <td>0.1</td>\n",
       "      <td>7</td>\n",
       "      <td>150</td>\n",
       "      <td>{'learning_rate': 0.1, 'max_depth': 7, 'n_estimators': 150}</td>\n",
       "      <td>0.973094</td>\n",
       "      <td>0.978475</td>\n",
       "      <td>0.970404</td>\n",
       "      <td>0.973070</td>\n",
       "      <td>0.970377</td>\n",
       "      <td>0.973084</td>\n",
       "      <td>0.002952</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>274.362426</td>\n",
       "      <td>1.695316</td>\n",
       "      <td>0.256189</td>\n",
       "      <td>0.007652</td>\n",
       "      <td>0.1</td>\n",
       "      <td>11</td>\n",
       "      <td>100</td>\n",
       "      <td>{'learning_rate': 0.1, 'max_depth': 11, 'n_estimators': 100}</td>\n",
       "      <td>0.972197</td>\n",
       "      <td>0.981166</td>\n",
       "      <td>0.973094</td>\n",
       "      <td>0.969479</td>\n",
       "      <td>0.968582</td>\n",
       "      <td>0.972904</td>\n",
       "      <td>0.004454</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2569.074754</td>\n",
       "      <td>1.074256</td>\n",
       "      <td>0.322658</td>\n",
       "      <td>0.086858</td>\n",
       "      <td>0.1</td>\n",
       "      <td>7</td>\n",
       "      <td>100</td>\n",
       "      <td>{'learning_rate': 0.1, 'max_depth': 7, 'n_estimators': 100}</td>\n",
       "      <td>0.973991</td>\n",
       "      <td>0.976682</td>\n",
       "      <td>0.970404</td>\n",
       "      <td>0.971275</td>\n",
       "      <td>0.971275</td>\n",
       "      <td>0.972725</td>\n",
       "      <td>0.002317</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "5     495.324935      2.785917         0.190579        0.043517   \n",
       "3    2620.852999      3.585602         0.303053        0.037751   \n",
       "1    1711.796690   1165.469866         0.287431        0.032164   \n",
       "2     274.362426      1.695316         0.256189        0.007652   \n",
       "0    2569.074754      1.074256         0.322658        0.086858   \n",
       "\n",
       "  param_learning_rate param_max_depth param_n_estimators  \\\n",
       "5                 0.1              15                150   \n",
       "3                 0.1              11                150   \n",
       "1                 0.1               7                150   \n",
       "2                 0.1              11                100   \n",
       "0                 0.1               7                100   \n",
       "\n",
       "                                                         params  \\\n",
       "5  {'learning_rate': 0.1, 'max_depth': 15, 'n_estimators': 150}   \n",
       "3  {'learning_rate': 0.1, 'max_depth': 11, 'n_estimators': 150}   \n",
       "1   {'learning_rate': 0.1, 'max_depth': 7, 'n_estimators': 150}   \n",
       "2  {'learning_rate': 0.1, 'max_depth': 11, 'n_estimators': 100}   \n",
       "0   {'learning_rate': 0.1, 'max_depth': 7, 'n_estimators': 100}   \n",
       "\n",
       "   split0_test_score  split1_test_score  split2_test_score  split3_test_score  \\\n",
       "5           0.973991           0.979372           0.973094           0.973070   \n",
       "3           0.973991           0.981166           0.971300           0.973070   \n",
       "1           0.973094           0.978475           0.970404           0.973070   \n",
       "2           0.972197           0.981166           0.973094           0.969479   \n",
       "0           0.973991           0.976682           0.970404           0.971275   \n",
       "\n",
       "   split4_test_score  mean_test_score  std_test_score  rank_test_score  \n",
       "5           0.970377         0.973981        0.002955                1  \n",
       "3           0.968582         0.973622        0.004199                2  \n",
       "1           0.970377         0.973084        0.002952                3  \n",
       "2           0.968582         0.972904        0.004454                4  \n",
       "0           0.971275         0.972725        0.002317                5  "
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gb = GradientBoostingClassifier()\n",
    "param ={'n_estimators': [100, 150],\n",
    "        'max_depth': [7, 11, 15],\n",
    "        'learning_rate': [0.1]}\n",
    "gs = GridSearchCV(gb, param, cv=5, n_jobs=-1)\n",
    "cv_fit = gs.fit(X_count_feat, data['label'])\n",
    "pd.DataFrame(cv_fit.cv_results_).sort_values('mean_test_score', ascending=False)[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(data[['body_text', 'body_len', 'punct%']], data['label'], test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vectorize text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_vect = TfidfVectorizer(analyzer=clean_text)\n",
    "tfidf_vect_fit = tfidf_vect.fit(X_train['body_text'])\n",
    "\n",
    "tfidf_train = tfidf_vect_fit.transform(X_train['body_text'])\n",
    "tfidf_test = tfidf_vect_fit.transform(X_test['body_text'])\n",
    "\n",
    "X_train_vect = pd.concat([X_train[['body_len', 'punct%']].reset_index(drop=True), pd.DataFrame(tfidf_train.toarray())], axis=1)\n",
    "X_test_vect = pd.concat([X_test[['body_len', 'punct%']].reset_index(drop=True), pd.DataFrame(tfidf_test.toarray())], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>body_len</th>\n",
       "      <th>punct%</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>...</th>\n",
       "      <th>7348</th>\n",
       "      <th>7349</th>\n",
       "      <th>7350</th>\n",
       "      <th>7351</th>\n",
       "      <th>7352</th>\n",
       "      <th>7353</th>\n",
       "      <th>7354</th>\n",
       "      <th>7355</th>\n",
       "      <th>7356</th>\n",
       "      <th>7357</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>40</td>\n",
       "      <td>12.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>24</td>\n",
       "      <td>25.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>64</td>\n",
       "      <td>7.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>94</td>\n",
       "      <td>12.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>138</td>\n",
       "      <td>4.3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4453</th>\n",
       "      <td>30</td>\n",
       "      <td>13.3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4454</th>\n",
       "      <td>42</td>\n",
       "      <td>9.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4455</th>\n",
       "      <td>88</td>\n",
       "      <td>5.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4456</th>\n",
       "      <td>94</td>\n",
       "      <td>11.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4457</th>\n",
       "      <td>63</td>\n",
       "      <td>17.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4458 rows Ã— 7360 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      body_len  punct%    0    1    2    3    4    5    6    7  ...  7348  \\\n",
       "0           40    12.5  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   0.0   \n",
       "1           24    25.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   0.0   \n",
       "2           64     7.8  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   0.0   \n",
       "3           94    12.8  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   0.0   \n",
       "4          138     4.3  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   0.0   \n",
       "...        ...     ...  ...  ...  ...  ...  ...  ...  ...  ...  ...   ...   \n",
       "4453        30    13.3  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   0.0   \n",
       "4454        42     9.5  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   0.0   \n",
       "4455        88     5.7  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   0.0   \n",
       "4456        94    11.7  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   0.0   \n",
       "4457        63    17.5  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   0.0   \n",
       "\n",
       "      7349  7350  7351  7352  7353  7354  7355  7356  7357  \n",
       "0      0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "1      0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "2      0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "3      0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "4      0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "...    ...   ...   ...   ...   ...   ...   ...   ...   ...  \n",
       "4453   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "4454   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "4455   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "4456   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "4457   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "\n",
       "[4458 rows x 7360 columns]"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_vect"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final evaluation of models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fit time: 1.292 / Predict_time: 0.097 ---- Precision: 1.0, Recall: 0.795, Accuracy: 0.972\n"
     ]
    }
   ],
   "source": [
    "rf = RandomForestClassifier(n_estimators=50, max_depth=None, n_jobs=-1)\n",
    "\n",
    "start = time.time()\n",
    "rf_model = rf.fit(X_train_vect, y_train)\n",
    "end = time.time()\n",
    "fit_time = end - start\n",
    "start = time.time()\n",
    "y_pred = rf_model.predict(X_test_vect)\n",
    "end = time.time()\n",
    "predict_time = end - start\n",
    "\n",
    "precision, recall, fscore, support = score(y_test, y_pred, pos_label='spam', average='binary')\n",
    "\n",
    "print('Fit time: {} / Predict_time: {} ---- Precision: {}, Recall: {}, Accuracy: {}'.\n",
    "      format(round(fit_time, 3), round(predict_time, 3), round(precision, 3), round(recall, 3), round((y_pred==y_test).sum() / len(y_test), 3)))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fit time: 235.294 / Predict_time: 0.159 ---- Precision: 0.941, Recall: 0.848, Accuracy: 0.972\n"
     ]
    }
   ],
   "source": [
    "gb = GradientBoostingClassifier(n_estimators=150, max_depth=11)\n",
    "\n",
    "start = time.time()\n",
    "gb_model = gb.fit(X_train_vect, y_train)\n",
    "end = time.time()\n",
    "fit_time = end - start\n",
    "start = time.time()\n",
    "y_pred = gb_model.predict(X_test_vect)\n",
    "end = time.time()\n",
    "predict_time = end - start\n",
    "\n",
    "precision, recall, fscore, support = score(y_test, y_pred, pos_label='spam', average='binary')\n",
    "\n",
    "print('Fit time: {} / Predict_time: {} ---- Precision: {}, Recall: {}, Accuracy: {}'.\n",
    "      format(round(fit_time, 3), round(predict_time, 3), round(precision, 3), round(recall, 3), round((y_pred==y_test).sum() / len(y_test), 3)))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
